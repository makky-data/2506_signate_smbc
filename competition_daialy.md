# SMBC Electricity Price Competition (2025)

##20250629
GDBTとSVMでアンサンブルトライ

## 20250628
特に何もしていない
## 20250627
    "total_load_actual_sin",
    "total_load_actual_cos",
    "total_loadactual_timeofday"
特徴量追加、ややスコアアップ
## 20250626

nb14で11台が出ていたので、それを再現。
特徴量が効いていたのか、（2015-08-01～2016-03-31を除くVer）が効いていたのかは検証中
（2015-08-01～2016-03-31を除くVer）が有効っぽい。
catboost,lgb,xgboostでアンサンブル

加重平均のアンサンブルをしたが、20ぐらいでスコア激悪
逐次予測のアンサンブルも試す。なぜか出力がおかしい。GPTにぶち込みまくっているから、自分でコードを読まないと...。

なんとか出力できて、10.8560758！！10切ることはかなわずだが、ベストスコア。

明日は特徴慮かな。

## 20250625
1. Val：8.261388940323398だった結果を投稿「catboost_v4」12.624
2. Catboostのラグ逐次実行 nb16→変わらず
3. パラメータチューニング？XGBoost
4. GPTに相談。XGboostで特徴量かなぁ。

特徴量の寄与度は確認したい。SHAPで確認し、上位30個の特徴量で再度回す
Valは4で、LBは
### 学習メモ

SHAPはゲーム理論のShapley値に基づいています。

各特徴量を「ゲームの参加者」とみなし、「予測値」という報酬をどう分配するか？を計算します。

SHAPは、すべての特徴量の組み合わせパターンを考慮して「その特徴量がいなかった場合との貢献度の差分」を公平に測ります。

✅ 特徴：どんなモデルにも使えるが、ツリー系（XGBoostやLightGBMなど）には高速計算アルゴリズムがある（TreeSHAP）
■shap.summary_plot
SHAP値が大きい程、予測結果への寄与度も大きいと考えられるため、横軸の分布が広い説明変数が重要と解釈できる。


■shap.plots.waterfall
![[Pasted image 20250625085324.png]]

赤色は正の値、青色は負の値に寄与していることが分かる。

## ✨ なぜ `log1p` が効くのか？

1. **ターゲットの歪度（右裾の重み）を押さえる**
    
    - 電力価格は「ときどきガツンと跳ね上がる」性質が強く、RMSE のような二乗誤差は大きな外れ値に過剰反応しがち。
        
    - `log1p` をかけると高い値ほど縮小されるので、モデルは「全体の傾向」を学びやすくなる。
        
2. **分散の安定化（等分散性の向上）**
    
    - もとのスケールだと「価格が高い時間帯ほどばらつき大」→ モデルが局所に引っ張られる。
        
    - ログ変換すると、各レンジでのばらつき幅がだいたい均一になる。
        
3. **相対誤差を最小化する効果**
    
    - RMSE をログ空間で最小化することは、元スケールでの**相対誤差**を小さくするのと近い。
        
    - たとえば 100→110 と 10→20 の両方を「同じ＋10」の絶対誤差で見るよりも、「10→20」のほうが被害大と考えるような振る舞い。
        
4. **0 や小さい値への対応**
    
    - まれに price_actual が 0 や極小になる場合、`log(price)` だと −∞ に落ちる。
        
    - `log1p`（`log(1 + x)`）なら 0→0、微小値→微小値、という性質で安定。
        

---

### 📝 まとめ

- **タイミング**：学習前の**前処理**でターゲット変換を行い、訓練・検証→予測全体に一貫して log1p を使う。
    
- **逆変換**：モデルの出力はすべて log1p 空間→予測後に必ず expm1() で戻す。
    
- **効く理由**：アウトライヤー抑制・分散安定化・相対誤差重視、かつ 0 値対応、というメリットがあるから。
## 20250624 nb15
totalloadactualのラグを試す
"total_load_actual_lag1",
    "total_load_actual_lag24",
    "total_load_actual_lag168",

[Pattern-1]  val RMSE = 4.2349→4.1705
[Pattern-3]  val RMSE = 3.7549→3.7515
[Pattern-4]  val RMSE = 4.1781→4.2667
微妙

log1pを試す
Val結果はかなり低い結果に、フルで学習させてLB確認→15でダメダメ
[Pattern-1]  val RMSE = 0.0638
[Pattern-3]  val RMSE = 0.0613
[Pattern-4]  val RMSE = 0.0657

log1pかつラグ逐次推測で実験→12.854
結局昨日の方が良いスコアになっている

nb16 catboostを試す（アンサンブル用）

mask_tr = df_train["time"].between("2015-01-01", "2017-09-30")
mask_va = df_train["time"].between("2017-10-01", "2017-12-31")

Val 13.490286094347274
LB:14.3928193
LBとの乖離が少ない！！

XGboost同様、全特徴量を追加して再度実装。
Val：3.33109018
LB：43.7027293 www爆死

この精度の差はなんなのだろうか...。



## 20250623 nb14
ラグ特徴量が死ぬほど効いていてびっくり。。。
[Base only]  val RMSE = 12.3939
[Add price_actual_lag1]  val RMSE = 4.6665
[Add price_actual_lag24]  val RMSE = 7.7932
[Add price_actual_lag168]  val RMSE = 8.2259

Val：RMSE = 3.4556
LB：24
でも爆死

GPTの指示に従い、逐次更新でラグ特徴量を更新していく形に変更。
→LB11ぐらいに！


## 20250622
nb13：PCAとSVR使っている人のを提出、8.5,,,すごい

## 20250621
まだ13.2282659しか出ない。
①一時11を出したモデルの再現に取り組もうか。。。
②XGBoostでよい結果が出ている人のものを再現してみる

2015年8月～2016年3月カットという方法もあるみたいでちょっと取り入れる。
nb12：
多少精度は改善したものの、13代で微妙。

パラメータをフォーラムでoputunaしたものに変更してみた。
かつ、特徴量も参考に。（そーいえばgeneration系以外入れていなかった）

nb13：PCAとSVR使っている人のをコピペしてみた


## 20250620
全特徴量を追加した下記をSubmit
submission_2025-06-19_full_全特徴量実装

これで様子をみて精度が良ければ、パターン①で学習、全情報で訓練→テストの方向性で良さそう（パターン③だと過学習なのかも？）
→結局パターン①のfull提出が一番良いのかも。一旦これで特徴量調整進める。
そしたら特徴量検討する。optunaも検討。

nb2にて特徴量探索のEDA
nb11にて特徴量エンジニアリング（XGBoost）

→過去Kaggle手法は後で辿ってみる

【EDA、特徴量エンジニアリング】
* 時間帯、夜に顕著な傾向があったので、夜とそれ以外で分けてみる
* 目的変数のLag特徴量（シンプルなシフトから、7期の移動平均）
* valencia_temp_diff 日中気温差と目的変数の相関を見る。高いものを採用
* demand_non_fossil_diff (需要量と化石燃料以外による発電量の差) GPTに視点を相談

[Base only]  val RMSE = 12.4188
×[Add season]  val RMSE = 12.5541
〇[Add time_of_day]  val RMSE = 12.3421
〇[Add is_weekend]  val RMSE = 12.1170
〇[Add is_holiday]  val RMSE = 12.3705
〇[Add is_long_wend]  val RMSE = 12.3793
〇[Add generation_sum]  val RMSE = 12.3868
×[Add fossil_share]  val RMSE = 12.6168
×[Add renewable_share]  val RMSE = 12.4595
×[Add time_of_day_only_night]  val RMSE = 12.3421
〇[Add valencia_temp_diff]  val RMSE = 11.3364
〇[Add season_isweekend]  val RMSE = 12.1991
〇[Add time_of_day_isweekend]  val RMSE = 12.1224
〇[Add temp_dev]  val RMSE = 11.9832
〇[Add fossil_share_diff1]  val RMSE = 12.3840
〇[Add renewable_share_diff1]  val RMSE = 12.2906
〇[Add fossil_share_dev7d]  val RMSE = 11.5958
〇[Add renewable_share_dev7d]  val RMSE = 11.5964
→フォーラムに記載の通り、valencia_temp_diffが結構効いている、7日のshareのラグ特徴量もまあまあではないか

この時のパラメータ
params_xgb = {
    "objective":"reg:squarederror",
    "learning_rate":0.05,
    "max_depth":36,
    "n_estimators":5000,
    "subsample":0.8,
    "colsample_bytree":0.8,
    "tree_method":"hist",
    "random_state":42,
    "eval_metric":"rmse"
}


今日の結果：
model3_上記全特徴量実装
* validation: 11.2853
* LB:13.8178467
full_上記全特徴量実装 1では9.78だったんだけどな...。
* LB:13.2282659
→model1で投稿：LB13.9961216

## 20250619
nb10 XGBoostで再トライ。Validationデータは3パターンで試してみる。
(5)で1回Submitするのも忘れずに→14でダメダメでした。

下記3パターン＆XGBoostで再トライ。
4パターンでのLBとの違いを比べてみた。特徴量は基本的にgeneration系のみ
①Train：2015-01-01～2016-12-31 Validation：2017-01-01~2017-12-31
* Validation結果：13.6421
* LB結果：15.7851314
②Train：2015年 Validation：2016年  Train：2015,2016年 Validation：2017年
* Validation結果：15.8975
* LB結果：→なんかうまくできなかった。モデル作成の方法をミスったからかな。
③Train：2015-01-01～2017-09-30 Validation：2017-10-01~2017-12-31
* Validation結果：14.4280
* LB結果：14.3998641 
④予測前に全てのデータで再訓練するように調整。
* LB結果：14.3994588

→q4でやるものがValidationとlbの差は一番少ない（ばらつきありの可能性もあるが）
q4採用かな...。

q4似て核特徴量を追加。
Running with: Base only
[Base only]  val RMSE = 14.4280
▶ Running with: Add season
[Add season]  val RMSE = 12.2299
▶ Running with: Add time_of_day
[Add time_of_day]  val RMSE = 13.9920
▶ Running with: Add is_weekend
[Add is_weekend]  val RMSE = 14.3413
▶ Running with: Add is_holiday
[Add is_holiday]  val RMSE = 14.2443
▶ Running with: Add is_long_wend
[Add is_long_wend]  val RMSE = 14.1701
▶ Running with: Add generation_sum
[Add generation_sum]  val RMSE = 14.5298
▶ Running with: Add fossil_share
[Add fossil_share]  val RMSE = 14.5177
▶ Running with: Add renewable_share
[Add renewable_share]  val RMSE = 14.4758

generation_sum、fossil_share,renewable_shareは効いていなさそう。
それ以外で回す。
Validation：10.9071
LB：14.2360162
改善全くなし＆差がすごいので、全ぶっぱfullのバージョンで特徴量全増しして試してみる。
はーーー、結局だめか。

## 20250618

nb8
なんか昨日試していた冬モデルがWorkしなくなった。
通常モデルで試しても14～15にとどまってしまう。
ValidationとLBとの乖離も相変わらず大きい。昨日の11は運だったのだろうか。
実験管理ががさつだったのが良くなかったな。

Adversarial validationを実施。AUC0.99でかなりの精度で見分けられている。
Generation系が大きく異なっていた。
重みづけという発想もあるみたい。テストデータに近づけるためにここまですると、汎化性能は微妙なのでは？と思いつつ実装してみるか。
調整がうまくいかず、心が折れそう。。。
何とか重み付きも実装できたが、ダメダメ。スコア14
フォーラムの投稿などを参考に、やり方を変えてみるべきなのかもしれない。（Validationの方法とか）

nb9
色々カットして、初期に戻り、Q3,Q4のみで再度やってみた。が結局14.4とかなり低い結果に。
明日はsubmission_2025-06-18 (5)のファイルを出す（特徴量を追加）Validationは7だから期待したいが。。。

| パターン                                                 | **Train（学習期間）**                                 | **Validation（検証期間）**                              | 仕組み / 狙い                 | メリット                         | デメリット                                     |
| ---------------------------------------------------- | ----------------------------------------------- | ------------------------------------------------- | ------------------------ | ---------------------------- | ----------------------------------------- |
| **① 固定 Q4 Hold-out**  <br>（最初の baseline）             | 2015-01-01 〜 2017-09-30                         | **2017-10-01 〜 12-31**                            | “直近 1 Q を丸ごと検証”          | ・実装シンプル  <br>・LB(2018)に比較的近い | ・検証が 1 fold=約 2,200 行で不安定  <br>・季節偏り（冬寄り） |
| **② Rolling 8-fold**                                 | 2015Q1〜17Q3 を **7 foldで train**                 | 各 fold の **直後 1 Q**  <br>（2015Q1〜2017Q4 計 8 fold） | “過去→未来” を段階的に検証          | ・全季節カバー  <br>・fold 平均で分散↓    | ・計算コスト↑  <br>・古い季節が LB と遠く乖離△             |
| **③ Expanding-Window**  <br>（17Q1〜Q4 val）            | 2015-01-01 〜 各 val 開始前                          | **2017Q1, Q2, Q3, Q4**  <br>4 fold                | “学習期間を伸ばしていく” 時系列 CV     | ・情報漏れなし  <br>・Q3/Q4 が LB に近い | ・Q1/Q2 が drift 大→CV-LB ギャップ拡大             |
| **④ 冬 / 非冬 ２モデル**                                    | mask=12,1,2 が冬  <br>それ以外が非冬                     | 各サブセット内で  <br>Expanding-Window（③と同じ）              | “冬だけ特性が違う” 仮説            | ・冬特化で RMSE↓                  | ・データ量が半減 → 過学習リスク                         |
| **⑤ Adversarial Validation**  <br>（train vs test 分類） | 2015-2017 全期間                                   | 2015-2017 全期間  <br>（目的 = is_test）                 | train/test の分布差を AUC で定量 | ・drift 列を特定                  | ・これは**検証ではなく診断**                          |
| **⑥ Weighted CV**  <br>(③ + ウェイト)                    | 2015-01-01 〜 val 開始前  <br>**weight = 1−p_test** | 2017Q1〜Q4  <br>(③と同じ fold)                        | test に似た行を重視して学習         | ・理論上 LB に寄る                  | ・実装複雑／改善小さめ                               |
| **⑦ Q3-Q4 限定 CV**  <br>（提案段階）                        | 2015-01-01 〜 2017-06-30                         | **2017Q3, Q4** のみ                                 | 検証を “LB に最も近い季節” へ絞る     | ・CV-LB ギャップ縮小期待              | ・fold 数 2 → 分散↑                           |
| **⑧ Drift 列でモデル分割**  <br>（提案段階）                      | ratio>閾値=“新電源優勢”  <br>それ以外                      | 同じ条件で各モデルに val                                    | 発電 mix が質的に異なる部分を分離      | ・極端 drift 行を隔離               | ・実装手間↑                                    |


### 学習メモ
Adversarial validationとは
学習で見えている世界と、LB が評価する世界が同じかどうかを事前に検査するレントゲン
テストデータか否かを目的変数とする二値分類モデル作成。
AUCで判定することで、1明確に分けられる＝全く異なると判断できる。

分布をみる時にはsns.kdeplotで
	ヒストグラムはビン幅で形が変わる。KDE はカーネル（正規分布など）で滑らかに推定
比率で調整しようとした理由→量的にみると異なるが、比率なら傾向は似ているのでは？という発想→似ていなかったが

## 20250617

nb7から

QuarterごとにValidationを実施するも改善なし。
LBとの乖離が相変わらず収まらない。
Q1だけ乖離があったので、冬の特徴をとらえきれていないことが原因だと推測される。
冬の祝日なども捉えられるように下記のコードも導入してみたが、相変わらず改善されず。

import holidays, numpy as np

es_holidays = holidays.Spain(years=[2015, 2016, 2017, 2018])

for df in (df_train, df_test):
    df["is_holiday"] = df["time"].dt.date.map(lambda d: 1 if d in es_holidays else 0)
    # 前後1日
    for s in [-1, 1]:
        df[f"hol_adj{s}"] = df["is_holiday"].shift(s).fillna(0)
    # 3連休以上を flag
    df["is_long_wend"] = (
        (df["is_holiday"].rolling(3, min_periods=1).sum() >= 2).astype(int)
    )

下記の理由から冬モデルを作成したところ、割とヒット！
LB11代に突入。
ただ内容を完全には理解しきれていないため勉強が必要。GPTに頼りまくっている。。。悔しい。
* 冬だけ RMSE が跳ねた (Fold-1 解析) → “冬を捉え切れていない” と判断
* テスト真値は無くても、OOF が冬で悪ければテスト冬でも悪いと推測
* 冬モデル分割 で OOF が改善 → LB も大幅改善

明日は、adversarial validationをするのもよいかもしれない。
冬モデルをつくることにあまり納得がいっていないので、Testデータと検証データの傾向を見てみたい。
AUCが0.5になればよいらしい。
## 20250616
■方針
kaggle内の似たようなコンペを参照する
ChatGPTと相談しながら進めてみる

nb06

テスト１年だから、検証１年だと思っていたけど、GPTによると下記の理由から直近の1Qでもよいらしい。

- **“時間的に一番近いデータ” がモデルの失敗パターンをよく再現する**
    
    - 2018 年テストの直前＝2017 Q4（10-12 月）は、 　
        
        - 需要・発電 mix・政策（CO₂価格など）の **水準** が 2018 年に最も近い
            
        - モデルが **外挿（未経験領域へ飛び出す）** リスクを最小に抑えられる
            
- **長い検証ほど「簡単な期間」が混ざって数値が甘く出やすい**
    
    - 春や秋は価格変動が小さく RMSE が下がりやすい ⇒ 過大評価
        
    - ――結果、CV11 → LB15 のようなギャップが起こる
        
- **RMSE は “観測数で加重平均”**
    
    - 検証を 3 か月に絞っても **点数の計算式は同じ**。
        
    - 3 か月ぶんでズレが⼩さければ、12 か月平均でも大抵ズレは小さい。
[こちら](https://techblog.insightedge.jp/entry/kaggle-optiver-solutions)の記事を見ても「Public LB・Private LBともに、評価用データは学習期間よりも後の時期のデータとなっており、CVのようなランダム分割ではなく、より新しいデータでバリデーションすることで評価期間での精度を正確に推測することが重要だった」とあるので良いのかも。

seedaveragingと2017年Q4のみで学習させるよう変更:14.12819で改善見られず...。過学習してるっぽい。

Seasonalでのバリデーションも試してみたが、8.6433と検証では出ているけど、LBでは13。これも過学習か。
つぎどうするべきかな。。。

あまりうまくいっていないので、いったん直近のもの（Q4）で学習できるものに戻しつつ、特徴量を調整してみようかな。リークの可能性が高い。→nb7準備済み

この人のものでやってみてもよいかも？？
https://signate.jp/competitions/1634/discussions/xgboost-baseline-lb107786

### 学び
![[Pasted image 20250616075201.png]]
Seed Averagingとは、**Seed(乱数)を変えながら同じモデルを何度も学習させ、その平均値**をサブミットとする手法で、上図におけるバリアンスを減らすことができます。
## 20250615

関数化して回しやすいようにする。

昨日実施したことまとめ
* 都市の地形を出す
	* マドリードが中心、その他地域は海沿いにある。
	* バルセロナ、バレンシアは東
	* ビルバオは北：雨全く降らないっぽい
	* セビリアは南
		* →風や降水量の違いがある？地域ごとの特性がありそうだが、それをどううまく使うべきなのかがわからない。
* 各都市の気温、最高・最低気温の時系列変化を見る
	* 多少の違いはあるが、大きな影響はなさそう。季節トレンドでカバーできそう。
* price_actualの時系列データを出し傾向をつかみたい
	* 年の傾向は似ている。季節性のトレンドがありそう
	* **→夏（6-8月）・冬（12-2月）・その他とかで特徴量を作る？**
* price_actual（目的変数）と各発電方式の相関を見る
	* 火力発電との相関が比較的高い。需要量ももちろん影響
	* 火力発電の稼働が増えるケースは？
		* 再生可能エネルギーが少ない（＝曇りや無風の時）
* price_actualの価格の外れ値はないかを見る
	* 2017年2月かなり高騰しているが何があったのか。
■特徴量検討のための仮説
* - 朝・昼・夜などの時間帯によって価格変動があるのではないか？
	* **→0時-6時、6時-12時、12時-18時、18時-24時とかで特徴量をつくる**
	* （派生）曜日の違いってあったりするのか？土日が高いみたいな。
	* →土日は逆に安くなっていた！ので、**weekdayとweekendで特徴量意味ありそう**
* 季節変動があるのではないか？
	* →しゅんかしゅうとうにかけて価格増加の傾向あり

スペインは再生エネルギーの開発が進んでおり、電力価格が比較的安定しているみたい。

1. 季節性追加：15.4752
2. 時間帯追加：14.9612
3. 週末フラグ追加：15.2274
4. 全部追加：15.0303

時間帯のみの方が良い...！？

■他の特徴量検討
* ディスカッションフォーラムで見た：train_selected['generation_sum'] = train_df[base_features].sum(axis=1)
→ベース特徴量が、generation系全て入っていたので真似してみる：15.2237
* 下記特徴量で実施したところ：14.6392（今のところベスト！）
    'year',
    'generation_fossil_gas',
    'generation_fossil_hard_coal',
    'generation_fossil_oil',
    'generation_hydro_pumped_storage_consumption',
    'generation_hydro_run_of_river_and_poundage',
    'generation_hydro_water_reservoir',
    'generation_other_renewable',
    'total_load_actual',
    "season",
    "time_of_day",
    "is_weekend"
* yearが悪さをしていたっぽい：14.1998（外挿になってた）
* lag特徴量試してみたがあまりうまくいかず：14.1998　nb5
* 「基準日からの日数」が結構重要な特徴量になるらしい
* パラメータいじいじ、generation_sum：13.9360
* fossilshare(火力発電の構成比):13.9803
* renewableshare:13.8947 



■特徴量アイデア
* 各地域の平均気温？
* ラグ特徴量？df["price_lag1"] = df["price_actual"].shift(1)
* 個別にモデルを作る方法ってワークするのかな？


### 学び
SHAP：“ゲーム理論で機械学習モデルを解体するレンチ”

外挿の意味が分からなかったのでチャッピーに。
✅ まとめ
用語	意味
内挿	学習データの間を予測する
外挿	学習データの外側（未来など）を予測する
危険性	外挿は信頼性が下がるので注意が必要
特に時系列コンペでは「外挿しても大丈夫な特徴量（周期性・気象など）」を使うことが重要です！


## 20250614
nb01
評価方法：RMSE

やっぱりそれなりに自分で整えて、FirstSubmitするの楽しい～～。
GPTに頼ってはいるけれど。

回帰と分類で使うものが異なることを知る。なんとかベースラインのFirstSubmit完了
時系列データだから、もっと気を付けないと。
RMSE：16.0945580

| 項目                             | 回帰 (Regressor)                 | 分類 (Classifier)                               |
| ------------------------------ | ------------------------------ | --------------------------------------------- |
| **モデルクラス**                     | `LGBMRegressor`                | `LGBMClassifier`                              |
| **目的関数 (objective)**           | `regression` / `regression_l2` | `binary` / `multiclass`                       |
| **評価指標 (metric)**              | `rmse`, `mae`, `r2`            | `binary_logloss`, `auc`, `accuracy` 等         |
| **出力メソッド**                     | `predict()` → 連続値              | `predict_proba()` → 各クラス確率, `predict()` → クラス |
| **スコアリング**                     | 平均誤差や決定係数など連続値評価               | 閾値ベースの精度・再現率・F1、ROC曲線                         |
| **クロスバリデーション**                 | `KFold`                        | `StratifiedKFold`（クラス分布を維持）                   |
| **不均衡データ対応**                   | 特別な対応なし（外れ値扱い注意）               | `scale_pos_weight`/`class_weight` でクラス重み付け    |
| **early_stopping_rounds 監視指標** | 検証セットの RMSE / MAE 等            | 検証セットの LogLoss / AUC 等                        |
| **多クラス対応パラメータ**                | —                              | `num_class`（クラス数）を指定                          |
| **確率キャリブレーション**                | 不要                             | `CalibratedClassifierCV` などで調整可               |
| **ハイパーパラメータの挙動**               | 木の深さ・葉数など回帰木として挙動              | 同じパラメータ名でもロス関数が異なるため最適値が変わる場合あり               |
次は、チュートリアルを参考に概要をさらにつかむ。

nb2
下記のように方針を立てながらEDAを実施


まず仮説を立て、それを確認するためのコードを検討    
目的：スペインマレーシアの電力価格の予測
■前提  
* まず、与えられた都市の地形を出す→地形コード？→DONE
* price_actualの時系列データを出し傾向をつかみたい→DONE
* 各都市の気温、最高・最低気温の時系列変化を見る→DONE
* price_actualと各発電方式の相関を見る→DONE
* price_actualの価格の外れ値はないかを見る→DONE

■仮説  
* 価格は需要と供給に基づくという点から何かしらの発電量と相関関係があるのではないか？→発電法によって価格弾力性は異なると考えられる
"generation_fossil_hard_coal","generation_fossil_brown_coal/lignite","total_load_actual","generation_fossil_gas"あたりの相関が比較的高い(0.35以上)  
* 朝・昼・夜などの時間帯によって価格変動があるのではないか？
* 春夏秋冬、季節性による価格変動があるのではないか？
* スペイン特有の大イベントなどがあると仮定すると、そのあたりの価格は常時より高くなるのではないか？
* 風力発電は、風速の強さの影響があるのではないか？
* 降雨量が高い時、
  
■特徴量作成のためのメモ
* 急激な価格変化があった前後のLagをとることで精度があがるのではないか？
* 再エネ比率（再エネ発電 / 総発電量）が有効な特徴量として働く可能性がある？

一旦、相関のあった特徴量にてモデルを回してみる。
が、バリデーションにて時系列のリークが出ているような気がするので、バリデーションの方法は検討しなければ。

6/15の実施事項
* 時系列に合わせたバリデーション
* 特徴量追加で回す
* 他特徴量の検討

■時系列データの注意点
Train：2015年1月1日～2017年12月31日 3年分
Test：2018年1月1日～2018年12月31日
* 説明変数として使ってよいデータは？
* SMBCルール：trainデータは全て学習OK、Testは、その日以前のデータしか使えない

* 古いデータは学習に使うべき？
→今回は大きく目的変数の傾向に差はなさそうなのでフルで使ってよさそうと判断
* 学習用データセットから検証用データをどう作るか？
→PPTにまとめた
![[Pasted image 20250614185156.png]]

nb3
1. 時系列を調整、特徴量を"generation_fossil_hard_coal","generation_fossil_brown_coal/lignite","total_load_actual","generation_fossil_gas"だけにして回す。
→結果：12.3832248
2. yearsを入れてみる。
→結果：12.5750991　落ちた
3. 実験的にFold1だけ、2017年を検証、2015、16年を学習としてみたら、15....とかだったから、やっぱりバリデーションは大事と確認できた

明日はnb4にて、特徴量作成に費やそうかな。